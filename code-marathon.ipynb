{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,Conv2D,BatchNormalization,Flatten,MaxPool2D,Activation,Dropout\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam,SGD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  test.csv\ttrain  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/code-marathon-ml/data/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d87c4422dabf77e7ebbd8ad2f10d36904027d26e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_name  n_sides\n",
      "0      0.png        5\n",
      "1      1.png        8\n",
      "2      2.png        4\n",
      "3      3.png        7\n",
      "4      4.png        4\n",
      "image_name    18432\n",
      "n_sides       18432\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('../input/code-marathon-ml/data/data/train.csv')\n",
    "print(df.head(5))\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "17a7630e6b671ecb4450c36fdee9061839eee5a7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_name  n_sides\n",
      "0   5290.png        3\n",
      "1  14022.png        3\n",
      "2   5747.png        5\n",
      "3  14163.png        5\n",
      "4   4841.png        4\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "eae6a46b597962c136d5df05e9e1c97e940578ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  test.csv\ttrain  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/code-marathon-ml/data/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e7ba2c000c31f808ac05b81136c42b8ff7d90802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 252, 252, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 252, 252, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 252, 252, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 84, 84, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 80, 80, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 80, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 43265     \n",
      "=================================================================\n",
      "Total params: 97,345\n",
      "Trainable params: 97,153\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(5,5),input_shape=(256,256,3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D((3,3)))\n",
    "model.add(Conv2D(64,(5,5)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D((3,3)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbf27354f9cc12e5ed4585b45dc338695415d568"
   },
   "source": [
    ",\n",
    "total size: 18432\n",
    "train: 16432\n",
    "test: 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "862f16a6c1a6b9471738ea24138cb0aaedcf3dd1"
   },
   "outputs": [],
   "source": [
    "path = '../input/code-marathon-ml/data/data/train/'\n",
    "file_names= df['image_name']\n",
    "def train_generator(batch_size):\n",
    "    count=0\n",
    "    while True:\n",
    "        X=[]\n",
    "        y=[]\n",
    "        line_count=0\n",
    "        for file_name in file_names[:16432]:\n",
    "            line_count+=1\n",
    "            img_path = path+file_name\n",
    "            img= image.load_img(img_path)\n",
    "            img= image.img_to_array(img)\n",
    "            img= img/255\n",
    "            X.append(img)\n",
    "            y.append(df.loc[df['image_name']== file_name].iloc[0,1])\n",
    "            count+=1\n",
    "            if count==batch_size or line_count == 16432 :\n",
    "                X= np.array(X)\n",
    "                y= np.array(y)\n",
    "                yield [X,y]\n",
    "                X=[]\n",
    "                y=[]\n",
    "                count=0\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "98ef38cd6de457abffc4b22722dae646dc97367f"
   },
   "outputs": [],
   "source": [
    "path = '../input/code-marathon-ml/data/data/train/'\n",
    "file_names= df['image_name']\n",
    "def val_generator(batch_size):\n",
    "    count=0\n",
    "    while True:\n",
    "        X=[]\n",
    "        y=[]\n",
    "        line_count=0\n",
    "        for file_name in file_names[16432:]:\n",
    "            line_count+=1\n",
    "            img_path = path+file_name\n",
    "            img= image.load_img(img_path)\n",
    "            img= image.img_to_array(img)\n",
    "            img= img/255\n",
    "            X.append(img)\n",
    "            y.append(df.loc[df['image_name']== file_name].iloc[0,1])\n",
    "            count+=1\n",
    "            if count==batch_size or line_count == 2000 :\n",
    "                X= np.array(X)\n",
    "                y= np.array(y)\n",
    "                yield [X,y]\n",
    "                X=[]\n",
    "                y=[]\n",
    "                count=0\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6ca68c2878ac8109d911bc3b53694c16cd7135fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 5 5 4 8 3 4 7 3]\n",
      "(10, 256, 256, 3)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "generator= train_generator(10)\n",
    "X,y= next(generator)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "34154d03c56ed29df07521c9d688d2d6d8cba8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 8 5 5 3 3 7 6 3]\n",
      "(10, 256, 256, 3)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "X,y= next(generator)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f35d5a7b7d8d7e0286f0b70b5cae660c1d6f49f7"
   },
   "outputs": [],
   "source": [
    "filepath=\"./model-{epoch:02d}-{val_loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True, verbose=1, mode='min')\n",
    "lr = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.4, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4ea4b76e5c665cfae77a9cbc3b8ed3bc01e57848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "129/129 [==============================] - 139s 1s/step - loss: 24.4846 - val_loss: 2.3189\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.31885, saving model to ./model-01-2.3189.h5\n",
      "Epoch 2/200\n",
      "129/129 [==============================] - 115s 895ms/step - loss: 2.3388 - val_loss: 1.9604\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.31885 to 1.96043, saving model to ./model-02-1.9604.h5\n",
      "Epoch 3/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 2.2520 - val_loss: 1.9049\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.96043 to 1.90494, saving model to ./model-03-1.9049.h5\n",
      "Epoch 4/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 2.1835 - val_loss: 1.8833\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.90494 to 1.88333, saving model to ./model-04-1.8833.h5\n",
      "Epoch 5/200\n",
      "129/129 [==============================] - 117s 903ms/step - loss: 2.1427 - val_loss: 1.8675\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.88333 to 1.86751, saving model to ./model-05-1.8675.h5\n",
      "Epoch 6/200\n",
      "129/129 [==============================] - 116s 900ms/step - loss: 2.0700 - val_loss: 1.9631\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.86751\n",
      "Epoch 7/200\n",
      "129/129 [==============================] - 116s 901ms/step - loss: 1.9639 - val_loss: 2.6998\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.86751\n",
      "Epoch 8/200\n",
      "129/129 [==============================] - 116s 899ms/step - loss: 1.8787 - val_loss: 3.4279\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.86751\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 9/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 1.6945 - val_loss: 2.3683\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.86751\n",
      "Epoch 10/200\n",
      "129/129 [==============================] - 116s 900ms/step - loss: 1.6421 - val_loss: 2.2353\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.86751\n",
      "Epoch 11/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.6096 - val_loss: 2.5088\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.86751\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "Epoch 12/200\n",
      "129/129 [==============================] - 117s 903ms/step - loss: 1.4769 - val_loss: 2.6038\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.86751\n",
      "Epoch 13/200\n",
      "129/129 [==============================] - 117s 903ms/step - loss: 1.4590 - val_loss: 2.4943\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.86751\n",
      "Epoch 14/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.4308 - val_loss: 2.4074\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.86751\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "Epoch 15/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 1.3819 - val_loss: 1.9054\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.86751\n",
      "Epoch 16/200\n",
      "129/129 [==============================] - 116s 903ms/step - loss: 1.3763 - val_loss: 1.5084\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.86751 to 1.50842, saving model to ./model-16-1.5084.h5\n",
      "Epoch 17/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.3485 - val_loss: 1.4735\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.50842 to 1.47351, saving model to ./model-17-1.4735.h5\n",
      "Epoch 18/200\n",
      "129/129 [==============================] - 117s 903ms/step - loss: 1.3570 - val_loss: 1.3684\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.47351 to 1.36839, saving model to ./model-18-1.3684.h5\n",
      "Epoch 19/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 1.3191 - val_loss: 1.3815\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.36839\n",
      "Epoch 20/200\n",
      "129/129 [==============================] - 117s 907ms/step - loss: 1.3131 - val_loss: 1.4391\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.36839\n",
      "Epoch 21/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.2994 - val_loss: 1.5817\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.36839\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "Epoch 22/200\n",
      "129/129 [==============================] - 117s 906ms/step - loss: 1.2709 - val_loss: 1.5704\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.36839\n",
      "Epoch 23/200\n",
      "129/129 [==============================] - 117s 908ms/step - loss: 1.2780 - val_loss: 1.5887\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.36839\n",
      "Epoch 24/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.2650 - val_loss: 1.5053\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.36839\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "Epoch 25/200\n",
      "129/129 [==============================] - 117s 909ms/step - loss: 1.2493 - val_loss: 1.2058\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.36839 to 1.20577, saving model to ./model-25-1.2058.h5\n",
      "Epoch 26/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.2355 - val_loss: 1.2029\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.20577 to 1.20293, saving model to ./model-26-1.2029.h5\n",
      "Epoch 27/200\n",
      "129/129 [==============================] - 117s 906ms/step - loss: 1.2588 - val_loss: 1.1869\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.20293 to 1.18686, saving model to ./model-27-1.1869.h5\n",
      "Epoch 28/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.2439 - val_loss: 1.2026\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.18686\n",
      "Epoch 29/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.2232 - val_loss: 1.2059\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.18686\n",
      "Epoch 30/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.2394 - val_loss: 1.1882\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.18686\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 31/200\n",
      "129/129 [==============================] - 116s 903ms/step - loss: 1.2165 - val_loss: 1.2376\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.18686\n",
      "Epoch 32/200\n",
      "129/129 [==============================] - 116s 903ms/step - loss: 1.2289 - val_loss: 1.2021\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.18686\n",
      "Epoch 33/200\n",
      "129/129 [==============================] - 117s 906ms/step - loss: 1.2304 - val_loss: 1.2166\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.18686\n",
      "Epoch 34/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.2158 - val_loss: 1.2250\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18686\n",
      "Epoch 35/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.2123 - val_loss: 1.2612\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.18686\n",
      "Epoch 36/200\n",
      "129/129 [==============================] - 117s 906ms/step - loss: 1.2090 - val_loss: 1.3155\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.18686\n",
      "Epoch 37/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.2123 - val_loss: 1.2655\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.18686\n",
      "Epoch 38/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.2155 - val_loss: 1.3189\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.18686\n",
      "Epoch 39/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.2027 - val_loss: 1.3077\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.18686\n",
      "Epoch 40/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.1874 - val_loss: 1.2938\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.18686\n",
      "Epoch 41/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 1.1867 - val_loss: 1.2369\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.18686\n",
      "Epoch 42/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.1771 - val_loss: 1.3436\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.18686\n",
      "Epoch 43/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.1797 - val_loss: 1.2163\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.18686\n",
      "Epoch 44/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.1596 - val_loss: 1.2857\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.18686\n",
      "Epoch 45/200\n",
      "129/129 [==============================] - 117s 903ms/step - loss: 1.1649 - val_loss: 1.3290\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.18686\n",
      "Epoch 46/200\n",
      "129/129 [==============================] - 117s 905ms/step - loss: 1.1661 - val_loss: 1.2914\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.18686\n",
      "Epoch 47/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.1580 - val_loss: 1.3140\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.18686\n",
      "Epoch 48/200\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 1.1419 - val_loss: 1.1910\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.18686\n",
      "Epoch 49/200\n",
      "129/129 [==============================] - 116s 902ms/step - loss: 1.1409 - val_loss: 1.2578\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.18686\n",
      "Epoch 50/200\n",
      " 82/129 [==================>...........] - ETA: 40s - loss: 1.1410"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size= 128\n",
    "train_gen= train_generator(batch_size)\n",
    "val_gen= val_generator(batch_size)\n",
    "train_rows= 16432\n",
    "val_rows= 2000\n",
    "train_steps= int(np.ceil(train_rows/batch_size))\n",
    "val_steps= int(np.ceil(val_rows/batch_size))\n",
    "# print(train_steps)\n",
    "# print(val_steps)\n",
    "history = model.fit_generator(generator=train_gen,steps_per_epoch= train_steps,validation_data=val_gen,callbacks=[checkpoint,lr], validation_steps=val_steps, epochs=epochs,verbose=1)\n",
    "model.save('./model.h5')\n",
    "output_data= pd.DataFrame.from_dict(history.history)\n",
    "output_data.to_csv('./loss_measuress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "db1fa0c1bc3c4047e7917d68bbe4ab366878a2a1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
